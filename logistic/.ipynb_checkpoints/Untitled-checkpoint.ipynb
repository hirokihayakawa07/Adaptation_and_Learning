{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/linux_home/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the spam dataset into train and test...\n",
      "Scaling the dataset...\n",
      "Running Logistic Regression with Fast Gradient Descent..\n",
      "Error on Training set =  0.06983695652173913\n",
      "Error on Test set =  0.1391304347826087\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Demo file demonstrating logistic regression\n",
    "# using fastgradientDescent on a real world dataset\n",
    "##########################################\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mpl\n",
    "import logRegFastGradientDescent\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#######################\n",
    "# Here, you can find the spam.data.txt in the repository\n",
    "# This data was obtained from https://statweb.stanford.edu/~tibs/ElemStatLearn/\n",
    "#######################\n",
    "\n",
    "data = pd.read_csv('spam.data.txt', header = None, sep = ' ')\n",
    "features = data[data.columns[0:57]]\n",
    "labels = data[57]\n",
    "labels[ labels == 0 ] = -1\n",
    "\n",
    "# Splitting dataset into train and test set (80:20)\n",
    "print(\"Splitting the spam dataset into train and test...\")\n",
    "featuresTrain = features[ 0 : int( 0.8 * len( features ) ) ]\n",
    "featuresTest = features[ int( 0.8 * len( features ) ) + 1: ]\n",
    "labelsTrain = labels[ 0 : int( 0.8 * len( labels ) ) ]\n",
    "labelsTest = labels[ int ( 0.8 * len( labels ) ) + 1: ]\n",
    "\n",
    "# Scaling the dataset\n",
    "print(\"Scaling the dataset...\")\n",
    "scaler = preprocessing.StandardScaler().fit(featuresTrain)\n",
    "featuresTrain = scaler.transform(featuresTrain)\n",
    "featuresTest = scaler.transform(featuresTest)\n",
    "\n",
    "lamda = 1\n",
    "maxIter = 1000\n",
    "InitStepSize = 0.01\n",
    "\n",
    "print(\"Running Logistic Regression with Fast Gradient Descent..\")\n",
    "# Running Fast Gradient Descent\n",
    "( lossFunctionValuesFastGrad, betaValuesFastGrad ) = logRegFastGradientDescent.fastGradDescent( featuresTrain, labelsTrain, 0.01, InitStepSize, maxIter )\n",
    "\n",
    "# Find Error on training set\n",
    "finalBeta = betaValuesFastGrad[-1]\n",
    "print(\"Error on Training set = \",  logRegFastGradientDescent.misclassificationError( finalBeta, featuresTrain, labelsTrain ) )\n",
    "\n",
    "# Find Error on test set\n",
    "print(\"Error on Test set = \",  logRegFastGradientDescent.misclassificationError( finalBeta, featuresTest, labelsTest ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 57)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "params = {\n",
    "    'rho': 1.0,\n",
    "    'mu':0.0001,\n",
    "    'M': 10,\n",
    "    'N': 500,\n",
    "    'maxit': 500,\n",
    "    'w_gt': np.random.randn(10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data set\n",
    "h = np.random.randn(params['M'],params['N'])\n",
    "gamma = 1 / (1 + np.exp(-np.transpose(h)@params['w_gt']))\n",
    "gamma = (gamma > 0.5)*2.0 -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the spam dataset into train and test...\n",
      "Scaling the dataset...\n",
      "Running Logistic Regression with Fast Gradient Descent..\n",
      "Error on Training set =  0.02\n",
      "Error on Test set =  0.030303030303030304\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Demo file demonstrating logistic regression\n",
    "# using fastgradientDescent on a real world dataset\n",
    "##########################################\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mpl\n",
    "import logRegFastGradientDescent\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#######################\n",
    "# Here, you can find the spam.data.txt in the repository\n",
    "# This data was obtained from https://statweb.stanford.edu/~tibs/ElemStatLearn/\n",
    "#######################\n",
    "\n",
    "features = np.transpose(h)\n",
    "labels = gamma\n",
    "\n",
    "# Splitting dataset into train and test set (80:20)\n",
    "print(\"Splitting the spam dataset into train and test...\")\n",
    "featuresTrain = features[ 0 : int( 0.8 * len( features ) ) ]\n",
    "featuresTest = features[ int( 0.8 * len( features ) ) + 1: ]\n",
    "labelsTrain = labels[ 0 : int( 0.8 * len( labels ) ) ]\n",
    "labelsTest = labels[ int ( 0.8 * len( labels ) ) + 1: ]\n",
    "\n",
    "# Scaling the dataset\n",
    "print(\"Scaling the dataset...\")\n",
    "scaler = preprocessing.StandardScaler().fit(featuresTrain)\n",
    "featuresTrain = scaler.transform(featuresTrain)\n",
    "featuresTest = scaler.transform(featuresTest)\n",
    "\n",
    "lamda = 1\n",
    "maxIter = 1000\n",
    "InitStepSize = 0.01\n",
    "\n",
    "print(\"Running Logistic Regression with Fast Gradient Descent..\")\n",
    "# Running Fast Gradient Descent\n",
    "( lossFunctionValuesFastGrad, betaValuesFastGrad ) = logRegFastGradientDescent.fastGradDescent( featuresTrain, labelsTrain, 0.01, InitStepSize, maxIter )\n",
    "\n",
    "# Find Error on training set\n",
    "finalBeta = betaValuesFastGrad[-1]\n",
    "print(\"Error on Training set = \",  logRegFastGradientDescent.misclassificationError( finalBeta, featuresTrain, labelsTrain ) )\n",
    "\n",
    "# Find Error on test set\n",
    "print(\"Error on Test set = \",  logRegFastGradientDescent.misclassificationError( finalBeta, featuresTest, labelsTest ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lossFunctionValuesFastGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.plot(range(1000),lossFunctionValuesFastGrad)\n",
    "mpl.yscale('log')\n",
    "mpl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2726389581568786"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lossFunctionValuesFastGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
